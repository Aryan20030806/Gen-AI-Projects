{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPS8FNfWTjp6N33xXZC0X7Y"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**GPT-3 FINETUNING USING GPT 4.1** ie To diff between two sports"],"metadata":{"id":"bO2hxnHNdXJD"}},{"cell_type":"markdown","source":["STEP 1 - INSTALLING THE REQ LIB"],"metadata":{"id":"FDHp_fumfVcY"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"fb9HlwOmacdH"},"outputs":[],"source":["!pip install --quiet openai"]},{"cell_type":"code","source":["!pip install --upgrade openai"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ku-uOwyweRuA","executionInfo":{"status":"ok","timestamp":1760273475879,"user_tz":-330,"elapsed":7710,"user":{"displayName":"Shubham Singh Parihar","userId":"15013670828682630891"}},"outputId":"8e3d65f7-c8e9-4004-f341-85a6898f322e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.109.1)\n","Collecting openai\n","  Downloading openai-2.3.0-py3-none-any.whl.metadata (29 kB)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.0)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.10)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n","Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n","Downloading openai-2.3.0-py3-none-any.whl (999 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m999.8/999.8 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: openai\n","  Attempting uninstall: openai\n","    Found existing installation: openai 1.109.1\n","    Uninstalling openai-1.109.1:\n","      Successfully uninstalled openai-1.109.1\n","Successfully installed openai-2.3.0\n"]}]},{"cell_type":"code","source":["from sklearn.datasets import fetch_20newsgroups # dataset from sklearn\n","import pandas as pd\n","import openai\n","import json\n","from sklearn.model_selection import train_test_split\n","\n","categories = ['rec.sport.baseball', 'rec.sport.hockey']\n","sports_dataset = fetch_20newsgroups(subset='train', shuffle=True, random_state=42, categories=categories)"],"metadata":{"id":"cCblYCAReX4_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["STEP 2 - DATA PREPRATION\n","\n","The data is divided into two columns according to the chatgpt example -\n","1) text - tht containes the email\n","2) labels - tht contains the name of sport"],"metadata":{"id":"1KGtQOYkfgV6"}},{"cell_type":"code","source":["texts = [text.strip().replace(\"\\n\", \" \") for text in sports_dataset.data]\n","labels = [sports_dataset.target_names[target].split('.')[-1] for target in sports_dataset.target]"],"metadata":{"id":"7dfH3g4ygbRt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# splitting of data into json files for easy storage with gpt 4.1 complaince\n","train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)\n","\n","def create_jsonl_gpt4(file_path, texts, labels):\n","    import json\n","    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n","        for text, label in zip(texts, labels):\n","            text_clean = text.replace(\"\\n\", \" \").strip()\n","            label_clean = label.strip()\n","            if not text_clean or not label_clean:\n","                continue\n","            record = {\n","                \"messages\": [\n","                    {\"role\": \"system\", \"content\": \"Classify the sport into either baseball or hockey.\"},\n","                    {\"role\": \"user\", \"content\": text_clean},\n","                    {\"role\": \"assistant\", \"content\": label_clean}\n","                ]\n","            }\n","            f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n","\n","create_jsonl_gpt4(\"sports_train_gpt4.jsonl\", train_texts, train_labels)\n","create_jsonl_gpt4(\"sports_valid_gpt4.jsonl\", val_texts, val_labels)\n","\n","\n","\n"],"metadata":{"id":"t5yUmNopoOo0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**STEP 3 - USING OPENAI TO UPLOAD FILES IN JSON FORMAT**"],"metadata":{"id":"GQWN_w_2CHKj"}},{"cell_type":"code","source":["# importing the\n","import os\n","os.environ[\"OPENAI_API_KEY\"] =  \"\""],"metadata":{"id":"LVdj2Kp8qTrk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Upload training file\n","!openai api files.create -f \"sports_prepared_train.jsonl\" -p fine-tune\n","\n","# Upload validation file\n","!openai api files.create -f \"sports_prepared_valid.jsonl\" -p fine-tune\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T6QoeZ2YwHjy","executionInfo":{"status":"ok","timestamp":1760282562765,"user_tz":-330,"elapsed":4047,"user":{"displayName":"Shubham Singh Parihar","userId":"15013670828682630891"}},"outputId":"e5ec3410-bee0-4668-eaec-df6e878ae3dd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Upload progress: 100% 1.82M/1.82M [00:00<00:00, 7.12Mit/s]\n","{\n","  \"id\": \"file-Ya2AwbNcyCUC8a1UwEYiyo\",\n","  \"bytes\": 1820561,\n","  \"created_at\": 1760282560,\n","  \"filename\": \"sports_prepared_train.jsonl\",\n","  \"object\": \"file\",\n","  \"purpose\": \"fine-tune\",\n","  \"status\": \"processed\",\n","  \"expires_at\": null,\n","  \"status_details\": null\n","}\n","Upload progress: 100% 414k/414k [00:00<00:00, 1.42Mit/s]\n","{\n","  \"id\": \"file-RosDc3NQ6YV8NXScKPmWHr\",\n","  \"bytes\": 414400,\n","  \"created_at\": 1760282562,\n","  \"filename\": \"sports_prepared_valid.jsonl\",\n","  \"object\": \"file\",\n","  \"purpose\": \"fine-tune\",\n","  \"status\": \"processed\",\n","  \"expires_at\": null,\n","  \"status_details\": null\n","}\n"]}]},{"cell_type":"markdown","source":["**STEP 4 - FINETUNING OF THE MODEL**"],"metadata":{"id":"44dqsKXjCR_E"}},{"cell_type":"code","source":["# calling the training function so tht it can take place in openai server\n","TRAINING_FILE_ID = \"file-Ya2AwbNcyCUC8a1UwEYiyo\" # key from above\n","VALIDATION_FILE_ID = \"file-RosDc3NQ6YV8NXScKPmWHr\" # key from above\n","\n","!openai api fine_tuning.jobs.create \\\n","  -F \"{TRAINING_FILE_ID}\" \\\n","  -V \"{VALIDATION_FILE_ID}\" \\\n","  -m \"gpt-4.1-2025-04-14\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tpdLIb0jrlUk","executionInfo":{"status":"ok","timestamp":1760282577830,"user_tz":-330,"elapsed":3368,"user":{"displayName":"Shubham Singh Parihar","userId":"15013670828682630891"}},"outputId":"1191daad-a1ae-4097-ecba-897802640928"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{\n","  \"id\": \"ftjob-bM7TsZtpFOM657lSBPmR6OeY\",\n","  \"created_at\": 1760282577,\n","  \"error\": {\n","    \"code\": null,\n","    \"message\": null,\n","    \"param\": null\n","  },\n","  \"fine_tuned_model\": null,\n","  \"finished_at\": null,\n","  \"hyperparameters\": {\n","    \"batch_size\": \"auto\",\n","    \"learning_rate_multiplier\": \"auto\",\n","    \"n_epochs\": \"auto\"\n","  },\n","  \"model\": \"gpt-4.1-2025-04-14\",\n","  \"object\": \"fine_tuning.job\",\n","  \"organization_id\": \"org-3seLMfR9IYGHHmACBVoy1Y8a\",\n","  \"result_files\": [],\n","  \"seed\": 1200733570,\n","  \"status\": \"validating_files\",\n","  \"trained_tokens\": null,\n","  \"training_file\": \"file-Ya2AwbNcyCUC8a1UwEYiyo\",\n","  \"validation_file\": \"file-RosDc3NQ6YV8NXScKPmWHr\",\n","  \"estimated_finish\": null,\n","  \"integrations\": [],\n","  \"metadata\": null,\n","  \"method\": {\n","    \"type\": \"supervised\",\n","    \"dpo\": null,\n","    \"reinforcement\": null,\n","    \"supervised\": {\n","      \"hyperparameters\": {\n","        \"batch_size\": \"auto\",\n","        \"learning_rate_multiplier\": \"auto\",\n","        \"n_epochs\": \"auto\"\n","      }\n","    }\n","  },\n","  \"user_provided_suffix\": null,\n","  \"usage_metrics\": null,\n","  \"shared_with_openai\": false,\n","  \"eval_id\": null\n","}\n"]}]},{"cell_type":"code","source":["# for checking the job status\n","!openai api fine_tuning.jobs.retrieve -i \"ftjob-bM7TsZtpFOM657lSBPmR6OeY\" # key from above\n"],"metadata":{"id":"_Y7xaM_GBlYX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# check if the fine tuning job is completed or not and then automaticallt test the model on sample data\n","import json, time, subprocess, openai\n","FT_JOB_ID = \"ftjob-bM7TsZtpFOM657lSBPmR6OeY\"\n","while True:\n","    job = json.loads(subprocess.run(\n","        [\"openai\", \"api\", \"fine_tuning.jobs.retrieve\", \"-i\", FT_JOB_ID],\n","        capture_output=True, text=True\n","    ).stdout)\n","    if job[\"status\"] in [\"succeeded\", \"failed\"]: break\n","    time.sleep(30)\n","if job[\"status\"] == \"succeeded\":\n","    model = job[\"fine_tuned_model\"]\n","    resp = openai.ChatCompletion.create(\n","        model=model,\n","        messages=[{\"role\":\"user\",\"content\":\"Classify this text: 'The hockey match was intense.'\"}]\n","        )\n","    print(resp['choices'][0]['message']['content'])\n","else:\n","    print(\"Fine-tuning failed\")\n"],"metadata":{"id":"alWFlRUJBn19"},"execution_count":null,"outputs":[]}]}