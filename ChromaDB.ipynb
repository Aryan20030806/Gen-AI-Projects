{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOR4kB4e8mzWdAPPR1C4pMp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**STEP 1 - DOWNLOADING THE REQ PACKAGES AND LIB**"],"metadata":{"id":"OOCKTq1aSfTb"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VOh-Ql7K7vf8","executionInfo":{"status":"ok","timestamp":1761493791252,"user_tz":-330,"elapsed":11777,"user":{"displayName":"Aryan Parihar","userId":"06637298487190752611"}},"outputId":"83c73ec6-720d-4f9a-c4ea-e102f985935f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting langchain-classic\n","  Downloading langchain_classic-1.0.0-py3-none-any.whl.metadata (3.9 kB)\n","Collecting langchain-core<2.0.0,>=1.0.0 (from langchain-classic)\n","  Downloading langchain_core-1.0.1-py3-none-any.whl.metadata (3.5 kB)\n","Collecting langchain-text-splitters<2.0.0,>=1.0.0 (from langchain-classic)\n","  Downloading langchain_text_splitters-1.0.0-py3-none-any.whl.metadata (2.6 kB)\n","Requirement already satisfied: langsmith<1.0.0,>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain-classic) (0.4.37)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-classic) (2.11.10)\n","Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-classic) (6.0.3)\n","Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-classic) (2.32.4)\n","Requirement already satisfied: sqlalchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-classic) (2.0.44)\n","Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-classic) (1.33)\n","Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-classic) (25.0)\n","Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-classic) (8.5.0)\n","Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-classic) (4.15.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.17->langchain-classic) (0.28.1)\n","Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.17->langchain-classic) (3.11.3)\n","Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.17->langchain-classic) (1.0.0)\n","Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.17->langchain-classic) (0.25.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic) (0.4.2)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->langchain-classic) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->langchain-classic) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->langchain-classic) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->langchain-classic) (2025.10.5)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy<3.0.0,>=1.4.0->langchain-classic) (3.2.4)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.17->langchain-classic) (4.11.0)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.17->langchain-classic) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.17->langchain-classic) (0.16.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain-classic) (3.0.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.17->langchain-classic) (1.3.1)\n","Downloading langchain_classic-1.0.0-py3-none-any.whl (1.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_core-1.0.1-py3-none-any.whl (467 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m467.1/467.1 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_text_splitters-1.0.0-py3-none-any.whl (33 kB)\n","Installing collected packages: langchain-core, langchain-text-splitters, langchain-classic\n","  Attempting uninstall: langchain-core\n","    Found existing installation: langchain-core 0.3.79\n","    Uninstalling langchain-core-0.3.79:\n","      Successfully uninstalled langchain-core-0.3.79\n","  Attempting uninstall: langchain-text-splitters\n","    Found existing installation: langchain-text-splitters 0.3.11\n","    Uninstalling langchain-text-splitters-0.3.11:\n","      Successfully uninstalled langchain-text-splitters-0.3.11\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","langchain 0.3.27 requires langchain-core<1.0.0,>=0.3.72, but you have langchain-core 1.0.1 which is incompatible.\n","langchain 0.3.27 requires langchain-text-splitters<1.0.0,>=0.3.9, but you have langchain-text-splitters 1.0.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed langchain-classic-1.0.0 langchain-core-1.0.1 langchain-text-splitters-1.0.0\n"]}],"source":["!pip install langchain-classic\n","!pip install chromadb openai tiktoken"]},{"cell_type":"code","source":["# the req lib\n","from langchain.vectorstores import Chroma\n","from langchain.embeddings import OpenAIEmbeddings\n","from langchain.llms import OpenAI\n","from langchain.document_loaders import DirectoryLoader\n","from langchain.document_loaders import TextLoader\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain.chains import RetrievalQA"],"metadata":{"id":"67bf2njfR8Nb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# use if u want to use a dropbox doc for the input data else upload mannualy\n","!wget -q = \"link of dropbox\"\n","!unzip -q \"path of the folder\" -d \"path of the folder but wihout the zip command\""],"metadata":{"id":"4bo-sPLePEFo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**STEP 2 - SETTING UP THE OPEN AI KEY**"],"metadata":{"id":"FlUqtu6-Px2W"}},{"cell_type":"code","source":["import os\n","os.environ['OPENAI_API_KEY'] = \"\""],"metadata":{"id":"RgkRkqmxPygv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**STEP 3 - LOADING THE DATA**"],"metadata":{"id":"7xOFxjY9P_WW"}},{"cell_type":"code","source":["loader = DirectoryLoader(\"/content/new_articles/\", glob = \"./*.txt\", loader_cls= TextLoader)\n","document = loader.load()"],"metadata":{"id":"2kswJxKXP-oM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**STEP 4 - CHUNKING**"],"metadata":{"id":"dYrf4YJDQSHm"}},{"cell_type":"code","source":["text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 200)\n","text = text_splitter.split_documents(document)"],"metadata":{"id":"B-Lu_LoXQLTE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**STEP 5 - CREATING THE DB**"],"metadata":{"id":"Lat6W93sQYxo"}},{"cell_type":"code","source":["from langchain import embeddings\n","persist_directory = 'db'\n","embedding = OpenAIEmbeddings()\n","vectordb = Chroma.from_documents(documents=text,\n","                                 embedding=embedding,\n","                                 persist_directory=persist_directory)"],"metadata":{"id":"c2TWKdQxQWND"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# saving the db to disk and loading it from the disc for usage\n","vectordb.persist()\n","vectordb = None\n","vectordb = Chroma(persist_directory=persist_directory,\n","                  embedding_function=embedding)"],"metadata":{"id":"SeNP1TYoQitF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**STEP 6 - MAKING THE RETRIVER FUNC**"],"metadata":{"id":"XEWTaYbDQr1J"}},{"cell_type":"code","source":["retriever = vectordb.as_retriever(search_kwargs={\"k\": 2}) # TO SET THE NUM OF OUTPUTS can also include the search type ie similarity search"],"metadata":{"id":"_vfkS848QrRR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**STEP 7 - MAKING QA CHAIN AS PER LANG CLASSIC**"],"metadata":{"id":"NauVMr6NRCJw"}},{"cell_type":"code","source":["llm=OpenAI()\n","qa_chain = RetrievalQA.from_chain_type(llm=OpenAI(),\n","                                  chain_type=\"stuff\",\n","                                  retriever=retriever,\n","                                  return_source_documents=True)"],"metadata":{"id":"EwIX4Bu5Q9So"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# printing the answer along with its reference sources.\n","def process_llm_response(llm_response):\n","    print(llm_response['result'])\n","    print('\\n\\nSources:')\n","    for source in llm_response[\"source_documents\"]:\n","        print(source.metadata['source'])"],"metadata":{"id":"iKlLIiuFRZw_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**STEP 8 - GENERATING THE ANS**"],"metadata":{"id":"zw6ivz6xRa7K"}},{"cell_type":"code","source":["query = \"How much money did Microsoft raise?\"\n","llm_response = qa_chain(query)\n","process_llm_response(llm_response)"],"metadata":{"id":"0TVoRuoURN5S"},"execution_count":null,"outputs":[]}]}