# üß† Gen-AI-Projects

A comprehensive collection of **Generative AI** and **Large Language Model (LLM)** projects implemented in Jupyter notebooks.  
This repository explores data preprocessing, vector databases, LLM model loading, LangChain pipelines, and document-based question-answering systems using modern open-source AI tools.

---

## üìÅ Repository Overview

| Notebook | Description |
|-----------|--------------|
| **GEN AI INTRO DATA FEEDING AND PREPROCESSING.ipynb** | Covers data ingestion, cleaning, and preprocessing steps for LLM applications. |
| **HUGGING_FACE.ipynb** | Demonstrates how to load, tokenize, and perform inference using Hugging Face Transformers and SentenceTransformers. |
| **Langchain.ipynb** | Implements the LangChain framework to build pipelines and custom chains for LLM-based apps. |
| **Llama2.ipynb** | Loads and uses Meta‚Äôs **LLaMA 2** model for text generation and Q&A tasks. |
| **Llama2 (quantized model).ipynb** | Implements a quantized (4-bit/8-bit) version of LLaMA 2 using BitsAndBytes for faster inference. |
| **LlamaIndex.ipynb** | Integrates **LlamaIndex (GPT Index)** for document-based Q&A and context retrieval. |
| **Mistral.ipynb** | Runs the **Mistral-7B** model and compares its output with other LLMs. |
| **Falcon.ipynb** | Uses **Falcon LLM** for text generation and conversational AI tasks. |
| **ChromaDB.ipynb** | Demonstrates **Chroma Vector Database** for embedding storage and semantic retrieval. |
| **Pinecone.ipynb** | Connects to **Pinecone** for vector-based document search and retrieval augmentation. |
| **weaviate.ipynb** | Implements **Weaviate** vector database for similarity search and retrieval pipelines. |
| **TEXT CLASSIFICATION USING SIMPLE ML MODEL.ipynb** | Uses traditional ML (TF-IDF + Logistic Regression) for text classification as a baseline model. |

---

## üöÄ Key Highlights

- End-to-end **Generative AI** workflow examples  
- Integration with **Vector Databases** (ChromaDB, Pinecone, Weaviate)  
- **LangChain** and **LlamaIndex** examples for building RAG pipelines  
- Model demos with **LLaMA 2**, **Mistral**, and **Falcon**  
- Hugging Face model loading and inference pipelines  
- Data preprocessing for efficient LLM input feeding  
- Includes simple ML comparison for text classification tasks  

---

## üß∞ Tech Stack

| Category | Tools / Libraries |
|-----------|-------------------|
| **Languages** | Python |
| **Frameworks** | LangChain, LlamaIndex |
| **LLMs** | LLaMA 2, Mistral, Falcon |
| **Databases** | ChromaDB, Pinecone, Weaviate |
| **Libraries** | Transformers, SentenceTransformers, BitsAndBytes |
| **ML Tools** | Scikit-learn, NumPy, Pandas, Matplotlib |
| **Deployment (future)** | Streamlit, FastAPI, Hugging Face Spaces |

---

## ‚öôÔ∏è Setup Instructions

### 1Ô∏è‚É£ Clone the repository
```bash
git clone https://github.com/Aryan20030806/Gen-AI-Projects.git
cd Gen-AI-Projects
